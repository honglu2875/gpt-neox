{
    "activation": "gelu",
    "apply_query_key_layer_scaling": false,
    "attention_dropout": 0,
    "attention_softmax_in_fp32": true,
    "bias_gelu_fusion": true,
    "checkpoint_activations": true,
    "checkpoint_factor": 2500,
    "checkpoint_num_layers": 1,
    "data_impl": "mmap",
    "deepspeed_slurm": true,
    "distributed_backend": "nccl",
    "eval_interval": 40000,
    "eval_iters": 10,
    "finetune": true,
    "fp16": {
        "enabled": true,
        "fp16": true,
        "hysteresis": 2,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "min_loss_scale": 1
    },
    "gpt_j_residual": true,
    "gpt_j_rotary_fn": true,
    "gpt_j_tied": true,
    "gradient_clipping": 1.0,
    "hf_gpt_j_compatible": true,
    "hidden_dropout": 0,
    "hidden_size": 2560,
    "init_method": "small_init",
    "label_data_paths": [
        "/mnt/nvme/home/honglu/diff_models_megatron/neox_diff_data/train_label_document"
    ],
    "launcher": "slurm",
    "load": "codegen_megatron_2b",
    "log_interval": 100,
    "lr_decay_iters": 2500,
    "lr_decay_style": "cosine",
    "max_position_embeddings": 2048,
    "min_lr": 0.000003,
    "model_parallel_size": 1,
    "no_weight_tying": true,
    "norm": "layernorm",
    "num_attention_heads": 32,
    "num_layers": 32,
    "num_workers": 1,
    "optimizer": {
        "params": {
            "betas": [
                0.9,
                0.999
            ],
            "eps": 0.00000001,
            "lr": 0.00003 
        },
        "type": "Adam"
    },
    "output_layer_init_method": "wang_init",
    "partition_activations": true,
    "pipe_parallel_size": 1,
    "pos_emb": "rotary",
    "prompt_end": "---prompt end---\n",
    "rotary_pct": 0.8,
    "save": "diff_2b",
    "scaled_upper_triang_masked_softmax_fusion": true,
    "seq_length": 2048,
    "steps_per_print": 10,
    "synchronize_each_layer": true,
    "test_data_paths": [
        "/mnt/nvme/home/honglu/diff_models_megatron/neox_diff_data/validation_text_document"
    ],
    "tokenizer_type": "HFGPT2Tokenizer",
    "train_data_paths": [
        "/mnt/nvme/home/honglu/diff_models_megatron/neox_diff_data/train_text_document"
    ],
    "train_iters": 10000,
    "train_micro_batch_size_per_gpu": 8,
    "use_wandb": true,
    "valid_data_paths": [
        "/mnt/nvme/home/honglu/diff_models_megatron/neox_diff_data/validation_text_document"
    ],
    "vocab_file": "Salesforce/codegen-350M-mono",
    "wall_clock_breakdown": true,
    "warmup": 0.01,
    "weight_decay": 0.1,
    "zero_optimization": {
        "allgather_bucket_size": 500000000,
        "allgather_partitions": true,
        "contiguous_gradients": true,
        "overlap_comm": true,
        "reduce_bucket_size": 500000000,
        "reduce_scatter": true,
        "stage": 1
    }
}
